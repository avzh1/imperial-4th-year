{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Tutorial\n",
    "\n",
    "In this RNN tutorial we will code an RNN Cell, before training a RNN model on the Google Speech Commands dataset for keyword spotting systems: \n",
    "\n",
    "The Google Speech Commands dataset can be found here: [*Speech Commands*](https://www.tensorflow.org/tutorials/sequences/audio_recognition) v0.02 [1] dataset.\n",
    "\n",
    "[1] Warden, P. (2018). [Speech commands: A dataset for limited-vocabulary speech recognition](https://arxiv.org/abs/1804.03209). *arXiv preprint arXiv:1804.03209.*\n",
    "\n",
    "The tutorial is meant as a gentle introduction to Coursework 3 which will use the same dataset.\n",
    "\n",
    "### Tutorial structure\n",
    "\n",
    "There are four questions provided, please fill in the missing code for each question between the comments as signalled in the workbook. \n",
    "\n",
    "After these four questions there is additional code that will train your model on the Google Speech Commands dataset so you can see your model in practise.\n",
    "\n",
    "### Installing packages\n",
    "\n",
    "Please note, if you do not have librosa, you may need to download this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we create a BasicRNNCell (Question 1):\n",
    "\n",
    "This should take input_data, and using the existing hidden state it should then return an updated hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n",
    "        super(BasicRNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.nonlinearity = nonlinearity\n",
    "        if self.nonlinearity not in [\"tanh\", \"relu\"]:\n",
    "            raise ValueError(\"Invalid nonlinearity selected for RNN.\")\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "            \n",
    "    def forward(self, input_data, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input_data.new_zeros(input_data.size(0), self.hidden_size, requires_grad=False)\n",
    "\n",
    "        activation = getattr(nn.functional, self.nonlinearity)\n",
    "        \n",
    "        ########################################################################\n",
    "        ## Q1) START OF YOUR CODE\n",
    "        ########################################################################\n",
    "        \n",
    "        hy = \n",
    "        \n",
    "        ########################################################################\n",
    "        ## END OF YOUR CODE\n",
    "        ########################################################################\n",
    "            \n",
    "        return hy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now incorporate our RNN memory cell into our RNN model below (Questions 2, 3 and 4):\n",
    "\n",
    "The following diagram below of a multi-layer RNN may be helpful:\n",
    "https://gblobscdn.gitbook.com/assets%2F-LIA3amopGH9NC6Rf0mA%2F-M4bJ-IWAKzglR0XHFwU%2F-M4bJ3L0dfAgvfE4itLW%2Fmulti-layer-rnn.png?alt=media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_cell_list = nn.ModuleList() # We append our BasicRNNCells to this list\n",
    "        \n",
    "        if mode == 'RNN_TANH':\n",
    "            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias,\n",
    "                                                   \"tanh\"))\n",
    "            \n",
    "            ########################################################################\n",
    "            ## Q2a) START OF YOUR CODE\n",
    "            ########################################################################\n",
    "                  \n",
    "            # We want to append BasicRNNCells to self.rnn_cell_list\n",
    "            # This should append the same number of BasicRNNCells as we have layers in the RNNModel\n",
    "\n",
    "            ########################################################################\n",
    "            ## END OF YOUR CODE\n",
    "            ########################################################################\n",
    "                \n",
    "                \n",
    "        elif mode == 'RNN_RELU':\n",
    "            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias,\n",
    "                                                   \"relu\"))\n",
    "            \n",
    "            ########################################################################\n",
    "            ## Q2b) START OF YOUR CODE (very similar to 2a)\n",
    "            ########################################################################\n",
    "            \n",
    "            # We want to append BasicRNNCells to self.rnn_cell_list\n",
    "            # This should append the same number of BasicRNNCells as we have layers in the RNNModel\n",
    "                \n",
    "            ########################################################################\n",
    "            ## END OF YOUR CODE\n",
    "            ########################################################################\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN mode selected.\")\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input_data, hx=None):\n",
    "\n",
    "        outs = []\n",
    "        X = list(input_data.permute(1, 0, 2))\n",
    "        h0 = [None] * self.num_layers if hx is None else list(hx)\n",
    "        \n",
    "        for j, l in enumerate(self.rnn_cell_list):\n",
    "            \n",
    "            ########################################################################\n",
    "            ## Q3) START OF YOUR CODE  (Hint: It may be easier to do Q4 first)\n",
    "            ########################################################################\n",
    "            \n",
    "            #Â Define the first value of hx_minus_one\n",
    "            \n",
    "            hx_minus_one = \n",
    "             \n",
    "            ########################################################################\n",
    "            ## END OF YOUR CODE\n",
    "            ########################################################################\n",
    "\n",
    "            for i in range(input_data.shape[1]):\n",
    "                \n",
    "                ########################################################################\n",
    "                ## Q4) START OF YOUR CODE\n",
    "                ########################################################################\n",
    "                \n",
    "                # We define hx, and update X for each input in our sequence.\n",
    "                # We also set our updated value of hx_minus_one\n",
    "                \n",
    "                hx = \n",
    "                hx_minus_one =\n",
    "                X[i] =\n",
    "                \n",
    "                ########################################################################\n",
    "                ## END OF YOUR CODE\n",
    "                ########################################################################\n",
    "                        \n",
    "        outs = X\n",
    "        \n",
    "        out = outs[-1].squeeze()\n",
    "       \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have completed the tutorial. Now try running the code below to see your model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechCommandsDataset(Dataset):\n",
    "    \"\"\"Google Speech Commands dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data files.\n",
    "            split    (string): In [\"train\", \"valid\", \"test\"].\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "\n",
    "        self.number_of_classes = len(self.get_classes())\n",
    "\n",
    "        self.class_to_file = defaultdict(list)\n",
    "\n",
    "        self.valid_filenames = self.get_valid_filenames()\n",
    "        self.test_filenames = self.get_test_filenames()\n",
    "\n",
    "        for c in self.get_classes():\n",
    "            file_name_list = sorted(os.listdir(self.root_dir + \"data_speech_commands_v0.02/\" + c))\n",
    "            for filename in file_name_list:\n",
    "                if split == \"train\":\n",
    "                    if (filename not in self.valid_filenames[c]) and (filename not in self.test_filenames[c]):\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"valid\":\n",
    "                    if filename in self.valid_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"test\":\n",
    "                    if filename in self.test_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid split name.\")\n",
    "\n",
    "        self.filepath_list = list()\n",
    "        self.label_list = list()\n",
    "        for cc, c in enumerate(self.get_classes()):\n",
    "            f_extension = sorted(list(self.class_to_file[c]))\n",
    "            l_extension = [cc for i in f_extension]\n",
    "            f_extension = [self.root_dir + \"data_speech_commands_v0.02/\" + c + \"/\" + filename for filename in f_extension]\n",
    "            self.filepath_list.extend(f_extension)\n",
    "            self.label_list.extend(l_extension)\n",
    "        self.number_of_samples = len(self.filepath_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number_of_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = np.zeros((16000, ), dtype=np.float32)\n",
    "\n",
    "        sample_file = self.filepath_list[idx]\n",
    "\n",
    "        sample_from_file = read(sample_file)[1]\n",
    "        sample[:sample_from_file.size] = sample_from_file\n",
    "        sample = sample.reshape((16000, ))\n",
    "        \n",
    "        sample = librosa.feature.mfcc(y=sample, sr=16000, hop_length=512, n_fft=2048).transpose().astype(np.float32)\n",
    "        \n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "    def get_classes(self):\n",
    "        return ['one', 'two', 'three']\n",
    "\n",
    "    def get_valid_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"data_speech_commands_v0.02/validation_list.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename\n",
    "\n",
    "    def get_test_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"data_speech_commands_v0.02/testing_list.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SURE THIS POINTS INSIDE THE DATASET FOLDER.\n",
    "dataset_folder = \"\" # this should change depending on where you have stored the data files\n",
    "\n",
    "train_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                      \"train\")\n",
    "valid_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                      \"valid\")\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                     \"test\")\n",
    "\n",
    "## YOU MAY CHANGE THE BATCH SIZE.\n",
    "batch_size = 57\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "valid_every_n_steps = 20\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parts of experiment code based on: https://github.com/emadRad/lstm-gru-pytorch\n",
    "import time\n",
    "seq_dim, input_dim = train_dataset[0][0].shape\n",
    "output_dim = 3\n",
    "\n",
    "hidden_dim = 32\n",
    "layer_dim = 4\n",
    "bias = True\n",
    "\n",
    "model = RNNModel(\"RNN_TANH\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_list = []\n",
    "iter = 0\n",
    "max_v_accuracy = 0\n",
    "reported_t_accuracy = 0\n",
    "max_t_accuracy = 0\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (audio, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(audio)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        iter += 1\n",
    "\n",
    "        if iter % valid_every_n_steps == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for audio, labels in valid_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                outputs = model(audio)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            v_accuracy = 100 * correct // total\n",
    "            \n",
    "            is_best = False\n",
    "            if v_accuracy >= max_v_accuracy:\n",
    "                max_v_accuracy = v_accuracy\n",
    "                is_best = True\n",
    "\n",
    "            if is_best:\n",
    "                for audio, labels in test_loader:\n",
    "                    if torch.cuda.is_available():\n",
    "                        audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "                    else:\n",
    "                        audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                    outputs = model(audio)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                    else:\n",
    "                        correct += (predicted == labels).sum()\n",
    "\n",
    "                t_accuracy = 100 * correct // total\n",
    "                reported_t_accuracy = t_accuracy\n",
    "\n",
    "            print('Iteration: {}. Loss: {}. V-Accuracy: {}  T-Accuracy: {}'.format(iter, loss.item(), v_accuracy, reported_t_accuracy))\n",
    "\n",
    "end = time.time()\n",
    "print(\"time cost: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
